#!/usr/bin/env python3
"""
Plot results from a CSV file generated by analyze_scores.py.

This script takes a CSV file with columns:
- predicted_lddt_scores: List of predicted lDDT scores
- true_lddt_scores: List of true lDDT scores  
- siamese_tm_score: Siamese model TM score prediction
- tmvec_tm_score: tm_vec model TM score prediction
- tmalign_tm_score: TM-align ground truth TM score

And generates the same plots as analyze_scores.py.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import ast
import sys
import argparse


def parse_score_list(score_str):
    """Parse a string representation of a list of scores."""
    try:
        # Handle different formats
        if isinstance(score_str, str):
            # Try ast.literal_eval first
            try:
                return ast.literal_eval(score_str)
            except:
                # Try eval as fallback for numpy arrays
                try:
                    result = eval(score_str)
                    # Convert numpy float32 to regular floats
                    if isinstance(result, list):
                        return [float(x) for x in result]
                    return result
                except:
                    print(f"Warning: Could not parse score string: {score_str[:100]}...")
                    return []
        elif isinstance(score_str, list):
            return score_str
        else:
            return []
    except Exception as e:
        print(f"Error parsing score string: {e}")
        return []


def plot_loss_distribution(all_errors, all_abs_errors, all_true_scores, all_predicted_scores, 
                          all_tm_errors, all_tm_abs_errors, all_tmvec_errors, all_tmvec_abs_errors,
                          all_true_tm_scores, all_predicted_tm_scores, output_prefix):
    """Plot the distribution of errors and absolute errors for both lDDT and TM scores."""
    # Set larger font sizes
    plt.rcParams.update({'font.size': 14})
    fig, axes = plt.subplots(2, 3, figsize=(18, 8))  # Shorter height: 8 instead of 12
    
    # === lDDT Score Plots ===
    # lDDT Error distribution
    axes[0, 0].set_xlim(-0.005, 0.005)  # Set x-axis limits first
    # Create shared bins for consistent bar widths
    lddt_error_bins = np.linspace(-0.005, 0.005, 31)  # 30 bins
    axes[0, 0].hist(all_errors, bins=lddt_error_bins, alpha=0.7, color='blue', edgecolor='black')
    axes[0, 0].set_title('lDDT Error Distribution')
    axes[0, 0].set_xlabel('Error')
    axes[0, 0].set_ylabel('Frequency')
    axes[0, 0].axvline(x=0, color='red', linestyle='--', alpha=0.7)
    
    # lDDT Absolute error distribution
    axes[0, 1].set_xlim(0, 0.005)  # Set x-axis limits first
    # Create shared bins for consistent bar widths
    lddt_abs_error_bins = np.linspace(0, 0.005, 31)  # 30 bins
    axes[0, 1].hist(all_abs_errors, bins=lddt_abs_error_bins, alpha=0.7, color='green', edgecolor='black')
    axes[0, 1].set_title('lDDT Absolute Error Distribution')
    axes[0, 1].set_xlabel('Absolute Error')
    axes[0, 1].set_ylabel('Frequency')
    
    # lDDT Predicted vs True scatter
    axes[0, 2].scatter(all_true_scores, all_predicted_scores, alpha=0.5, s=1)
    axes[0, 2].set_title('lDDT Predicted vs True')
    axes[0, 2].set_xlabel('True lDDT Score')
    axes[0, 2].set_ylabel('Predicted lDDT Score')
    axes[0, 2].plot([0, 1], [0, 1], 'r--', alpha=0.7)  # Perfect prediction line
    
    # === TM Score Plots ===
    # TM Error distribution (Siamese vs tm_vec)
    axes[1, 0].set_xlim(-0.3, 0.3)  # Set x-axis limits first
    # Create shared bins for consistent bar widths
    error_bins = np.linspace(-0.3, 0.3, 31)  # 30 bins
    axes[1, 0].hist(all_tm_errors, bins=error_bins, alpha=0.4, color='orange', edgecolor='black', label='our model')
    axes[1, 0].hist(all_tmvec_errors, bins=error_bins, alpha=0.4, color='cyan', edgecolor='black', label='TM-vec')
    axes[1, 0].set_title('TM Score Error Distribution')
    axes[1, 0].set_xlabel('Error')
    axes[1, 0].set_ylabel('Frequency')
    axes[1, 0].axvline(x=0, color='red', linestyle='--', alpha=0.7)
    axes[1, 0].legend()
    
    # TM Absolute error distribution (Siamese vs tm_vec)
    axes[1, 1].set_xlim(0, 0.3)  # Set x-axis limits first
    # Create shared bins for consistent bar widths
    abs_error_bins = np.linspace(0, 0.3, 31)  # 30 bins
    axes[1, 1].hist(all_tm_abs_errors, bins=abs_error_bins, alpha=0.4, color='magenta', edgecolor='black', label='our model')
    axes[1, 1].hist(all_tmvec_abs_errors, bins=abs_error_bins, alpha=0.4, color='blue', edgecolor='black', label='TM-vec')
    axes[1, 1].set_title('TM Score Absolute Error Distribution')
    axes[1, 1].set_xlabel('Absolute Error')
    axes[1, 1].set_ylabel('Frequency')
    axes[1, 1].legend()
    
    # TM Predicted vs True scatter
    axes[1, 2].scatter(all_true_tm_scores, all_predicted_tm_scores, alpha=0.5, s=1)
    axes[1, 2].set_title('TM Score Predicted vs True')
    axes[1, 2].set_xlabel('True TM Score')
    axes[1, 2].set_ylabel('Predicted TM Score')
    axes[1, 2].plot([0, 1], [0, 1], 'r--', alpha=0.7)  # Perfect prediction line
    
    plt.tight_layout()
    plt.savefig(f'{output_prefix}_loss_distribution.png', dpi=300, bbox_inches='tight')
    plt.close()
    # Reset font size to default
    plt.rcParams.update({'font.size': 10})
    print(f"Saved loss distribution plot to: {output_prefix}_loss_distribution.png")


def main():
    parser = argparse.ArgumentParser(description="Plot results from analyze_scores.py CSV output")
    parser.add_argument('input_csv', type=str, help='Input CSV file from analyze_scores.py')
    parser.add_argument('--output-prefix', type=str, default=None, 
                       help='Output prefix for plots (default: input_csv basename)')
    args = parser.parse_args()
    
    input_csv = args.input_csv
    if args.output_prefix:
        output_prefix = args.output_prefix
    else:
        output_prefix = input_csv.replace('.csv', '')
    
    print(f"Reading CSV file: {input_csv}")
    df = pd.read_csv(input_csv)
    print(f"Found {len(df)} rows in CSV")
    
    # Initialize lists to collect all data for statistics
    all_predicted_scores = []
    all_true_scores = []
    all_errors = []
    all_abs_errors = []
    # TM score tracking
    all_predicted_tm_scores = []  # Siamese model predictions
    all_tmvec_tm_scores = []      # tm_vec model predictions
    all_true_tm_scores = []       # TM-align ground truth
    all_tm_errors = []            # Siamese model errors
    all_tm_abs_errors = []        # Siamese model absolute errors
    all_tmvec_errors = []         # tm_vec model errors
    all_tmvec_abs_errors = []     # tm_vec model absolute errors
    protein_stats = []  # List to store per-protein statistics
    processed_variants = 0
    
    print("Processing CSV data...")
    for idx, row in df.iterrows():
        try:
            print(f"Processing row {idx+1}/{len(df)}: {row.get('PID', f'Row {idx+1}')}")
            
            # Parse lDDT scores
            predicted_lddt_scores = parse_score_list(row.get('predicted_lddt_scores', []))
            true_lddt_scores = parse_score_list(row.get('true_lddt_scores', []))
            
            if not predicted_lddt_scores or not true_lddt_scores:
                print(f"  Skipping: missing lDDT scores")
                continue
            
            # Get pre-computed statistics from CSV
            mae = float(row.get('mae', 0))
            mse = float(row.get('mse', 0))
            rmse = float(row.get('rmse', 0))
            std_error = float(row.get('std_error', 0))
            std_abs_error = float(row.get('std_abs_error', 0))
            correlation = float(row.get('correlation', 0))
            
            # Get TM scores and errors from CSV
            siamese_tm_score = float(row.get('siamese_tm_score', 0))
            tmvec_tm_score = float(row.get('tmvec_tm_score', 0))
            tmalign_tm_score = float(row.get('tmalign_tm_score', 0))
            siamese_tm_error = float(row.get('siamese_tm_error', 0))
            siamese_tm_abs_error = float(row.get('siamese_tm_abs_error', 0))
            tmvec_tm_error = float(row.get('tmvec_tm_error', 0))
            tmvec_tm_abs_error = float(row.get('tmvec_tm_abs_error', 0))
            
            # Check if TM-align score is valid (not 0 or None)
            if tmalign_tm_score <= 0:
                print(f"  Skipping TM score analysis: invalid TM-align score ({tmalign_tm_score})")
                valid_tm_score = False
            else:
                valid_tm_score = True
            
            # Store per-protein statistics (use values from CSV)
            protein_stats.append({
                'PID': row.get('PID', f'Row_{idx+1}'),
                'sequence_length': int(row.get('sequence_length', len(predicted_lddt_scores))),
                'predicted_mean_lddt': float(row.get('predicted_mean_lddt', np.mean(predicted_lddt_scores))),
                'true_mean_lddt': float(row.get('true_mean_lddt', np.mean(true_lddt_scores))),
                'siamese_tm_score': siamese_tm_score,
                'tmvec_tm_score': tmvec_tm_score,
                'tmalign_tm_score': tmalign_tm_score,
                'siamese_tm_error': siamese_tm_error,
                'siamese_tm_abs_error': siamese_tm_abs_error,
                'tmvec_tm_error': tmvec_tm_error,
                'tmvec_tm_abs_error': tmvec_tm_abs_error,
                'mae': mae,
                'mse': mse,
                'rmse': rmse,
                'std_error': std_error,
                'std_abs_error': std_abs_error,
                'correlation': correlation,
                'description': row.get("description", "")
            })
            
            # Collect TM score errors for plotting (only if valid)
            if valid_tm_score:
                all_tm_errors.append(siamese_tm_error)
                all_tm_abs_errors.append(siamese_tm_abs_error)
                all_tmvec_errors.append(tmvec_tm_error)
                all_tmvec_abs_errors.append(tmvec_tm_abs_error)
            processed_variants += 1
            
            # Print summary with statistics
            print(f"  Predicted mean lDDT: {row.get('predicted_mean_lddt', np.mean(predicted_lddt_scores)):.4f}")
            print(f"  True mean lDDT: {row.get('true_mean_lddt', np.mean(true_lddt_scores)):.4f}")
            print(f"  Siamese TM score: {siamese_tm_score:.4f}")
            print(f"  tm_vec TM score: {tmvec_tm_score:.4f}")
            print(f"  TM-align TM score: {tmalign_tm_score:.4f}")
            if valid_tm_score:
                print(f"  Siamese TM error: {siamese_tm_error:.4f}")
                print(f"  tm_vec TM error: {tmvec_tm_error:.4f}")
            print(f"  lDDT MAE: {mae:.4f}")
            print(f"  lDDT RMSE: {rmse:.4f}")
            print(f"  lDDT Correlation: {correlation:.4f}")
            
        except Exception as e:
            print(f"Error processing row {idx+1}: {e}")
            continue

    # Convert TM score error arrays for plotting
    all_tm_errors = np.array(all_tm_errors)
    all_tm_abs_errors = np.array(all_tm_abs_errors)
    all_tmvec_errors = np.array(all_tmvec_errors)
    all_tmvec_abs_errors = np.array(all_tmvec_abs_errors)

    # Save per-protein statistics to CSV
    protein_stats_csv = f"{output_prefix}_protein_statistics.csv"
    protein_stats_df = pd.DataFrame(protein_stats)
    protein_stats_df.to_csv(protein_stats_csv, index=False)
    print(f"Saved per-protein statistics to: {protein_stats_csv}")

    # Compute overall statistics from the CSV data
    # For lDDT, we need to compute overall stats from individual protein stats
    if protein_stats:
        overall_mae = np.mean([p['mae'] for p in protein_stats])
        overall_mse = np.mean([p['mse'] for p in protein_stats])
        overall_rmse = np.mean([p['rmse'] for p in protein_stats])
        overall_std_error = np.mean([p['std_error'] for p in protein_stats])
        overall_std_abs_error = np.mean([p['std_abs_error'] for p in protein_stats])
        overall_correlation = np.mean([p['correlation'] for p in protein_stats])
    else:
        overall_mae = overall_mse = overall_rmse = overall_std_error = overall_std_abs_error = overall_correlation = 0.0
    
    # For TM scores, compute from collected error arrays
    if len(all_tm_errors) > 0:
        overall_siamese_tm_mae = np.mean(all_tm_abs_errors)
        overall_siamese_tm_mse = np.mean(all_tm_errors ** 2)
        overall_siamese_tm_rmse = np.sqrt(overall_siamese_tm_mse)
        overall_siamese_tm_std_error = np.std(all_tm_errors)
        overall_siamese_tm_std_abs_error = np.std(all_tm_abs_errors)
        overall_siamese_tm_correlation = 0.0  # Can't compute correlation from errors alone
    else:
        overall_siamese_tm_mae = overall_siamese_tm_mse = overall_siamese_tm_rmse = overall_siamese_tm_std_error = overall_siamese_tm_std_abs_error = overall_siamese_tm_correlation = 0.0
    
    if len(all_tmvec_errors) > 0:
        overall_tmvec_tm_mae = np.mean(all_tmvec_abs_errors)
        overall_tmvec_tm_mse = np.mean(all_tmvec_errors ** 2)
        overall_tmvec_tm_rmse = np.sqrt(overall_tmvec_tm_mse)
        overall_tmvec_tm_std_error = np.std(all_tmvec_errors)
        overall_tmvec_tm_std_abs_error = np.std(all_tmvec_abs_errors)
        overall_tmvec_tm_correlation = 0.0  # Can't compute correlation from errors alone
    else:
        overall_tmvec_tm_mae = overall_tmvec_tm_mse = overall_tmvec_tm_rmse = overall_tmvec_tm_std_error = overall_tmvec_tm_std_abs_error = overall_tmvec_tm_correlation = 0.0

    print(f"\n=== OVERALL STATISTICS ===")
    print(f"Total protein variants processed: {processed_variants}")
    print(f"Total residues processed: {len(all_predicted_scores)}")
    print(f"Valid TM score pairs: {len(all_tm_errors)}")

    print(f"\n=== lDDT STATISTICS ===")
    print(f"lDDT MAE: {overall_mae:.4f}")
    print(f"lDDT MSE: {overall_mse:.4f}")
    print(f"lDDT RMSE: {overall_rmse:.4f}")
    print(f"lDDT Standard Deviation of Errors: {overall_std_error:.4f}")
    print(f"lDDT Standard Deviation of Absolute Errors: {overall_std_abs_error:.4f}")
    print(f"lDDT Correlation: {overall_correlation:.4f}")

    print(f"\n=== TM SCORE STATISTICS (vs TM-align) ===")
    print(f"Siamese Model:")
    print(f"  TM MAE: {overall_siamese_tm_mae:.4f}")
    print(f"  TM MSE: {overall_siamese_tm_mse:.4f}")
    print(f"  TM RMSE: {overall_siamese_tm_rmse:.4f}")
    print(f"  TM Standard Deviation of Errors: {overall_siamese_tm_std_error:.4f}")
    print(f"  TM Standard Deviation of Absolute Errors: {overall_siamese_tm_std_abs_error:.4f}")
    print(f"  TM Correlation: {overall_siamese_tm_correlation:.4f}")

    print(f"\ntm_vec Model:")
    print(f"  TM MAE: {overall_tmvec_tm_mae:.4f}")
    print(f"  TM MSE: {overall_tmvec_tm_mse:.4f}")
    print(f"  TM RMSE: {overall_tmvec_tm_rmse:.4f}")
    print(f"  TM Standard Deviation of Errors: {overall_tmvec_tm_std_error:.4f}")
    print(f"  TM Standard Deviation of Absolute Errors: {overall_tmvec_tm_std_abs_error:.4f}")
    print(f"  TM Correlation: {overall_tmvec_tm_correlation:.4f}")

    # Create loss distribution plot
    # For lDDT, we need to collect all scores for plotting
    all_predicted_scores = []
    all_true_scores = []
    all_errors = []
    all_abs_errors = []
    
    for idx, row in df.iterrows():
        try:
            predicted_lddt_scores = parse_score_list(row.get('predicted_lddt_scores', []))
            true_lddt_scores = parse_score_list(row.get('true_lddt_scores', []))
            
            if predicted_lddt_scores and true_lddt_scores:
                all_predicted_scores.extend(predicted_lddt_scores[:len(true_lddt_scores)])
                all_true_scores.extend(true_lddt_scores[:len(predicted_lddt_scores)])
        except:
            continue
    
    all_predicted_scores = np.array(all_predicted_scores)
    all_true_scores = np.array(all_true_scores)
    all_errors = all_predicted_scores - all_true_scores
    all_abs_errors = np.abs(all_errors)
    
    # For TM scores, we need to collect scores for plotting
    all_predicted_tm_scores = []
    all_true_tm_scores = []
    
    for idx, row in df.iterrows():
        try:
            siamese_tm_score = float(row.get('siamese_tm_score', 0))
            tmalign_tm_score = float(row.get('tmalign_tm_score', 0))
            
            if tmalign_tm_score > 0:
                all_predicted_tm_scores.append(siamese_tm_score)
                all_true_tm_scores.append(tmalign_tm_score)
        except:
            continue
    
    all_predicted_tm_scores = np.array(all_predicted_tm_scores)
    all_true_tm_scores = np.array(all_true_tm_scores)
    
    plot_loss_distribution(all_errors, all_abs_errors, all_true_scores, all_predicted_scores, 
                          all_tm_errors, all_tm_abs_errors, all_tmvec_errors, all_tmvec_abs_errors,
                          all_true_tm_scores, all_predicted_tm_scores, output_prefix)

    print(f"\nPlots and statistics generated successfully!")
    print(f"Output files:")
    print(f"  - {output_prefix}_loss_distribution.png")
    print(f"  - {output_prefix}_protein_statistics.csv")


if __name__ == "__main__":
    main() 